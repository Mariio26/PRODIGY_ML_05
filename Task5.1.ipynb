{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694e0e4b-bcbe-4ebd-8849-0d7e0ae91bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from tensorflow.keras.applications import MobileNetV2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6824fb86-71cd-4415-9c96-949705647720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Total images found: 2500\n",
      "First 10 image files:\n",
      "['training\\\\food\\\\0.jpg', 'training\\\\food\\\\1.jpg', 'training\\\\food\\\\10.jpg', 'training\\\\food\\\\100.jpg', 'training\\\\food\\\\1000.jpg', 'training\\\\food\\\\1001.jpg', 'training\\\\food\\\\1002.jpg', 'training\\\\food\\\\1003.jpg', 'training\\\\food\\\\1004.jpg', 'training\\\\food\\\\1005.jpg']\n",
      "First 10 entries in calorie_data:\n",
      "[{'filename': 'training\\\\food\\\\0.jpg', 'calorie': 229}, {'filename': 'training\\\\food\\\\1.jpg', 'calorie': 361}, {'filename': 'training\\\\food\\\\10.jpg', 'calorie': 92}, {'filename': 'training\\\\food\\\\100.jpg', 'calorie': 52}, {'filename': 'training\\\\food\\\\1000.jpg', 'calorie': 473}, {'filename': 'training\\\\food\\\\1001.jpg', 'calorie': 109}, {'filename': 'training\\\\food\\\\1002.jpg', 'calorie': 59}, {'filename': 'training\\\\food\\\\1003.jpg', 'calorie': 477}, {'filename': 'training\\\\food\\\\1004.jpg', 'calorie': 246}, {'filename': 'training\\\\food\\\\1005.jpg', 'calorie': 75}]\n",
      "First few rows of calorie_df:\n",
      "                 filename  calorie\n",
      "0     training\\food\\0.jpg      229\n",
      "1     training\\food\\1.jpg      361\n",
      "2    training\\food\\10.jpg       92\n",
      "3   training\\food\\100.jpg       52\n",
      "4  training\\food\\1000.jpg      473\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Verify GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = 'Food_5K'\n",
    "\n",
    "# Check and print the existing subdirectories\n",
    "subdirectories = []\n",
    "for subset in ['training', 'validation', 'evaluation']:\n",
    "    subset_path = os.path.join(dataset_path, subset)\n",
    "    if os.path.exists(subset_path):\n",
    "        subdirectories.append(subset_path)\n",
    "    else:\n",
    "        print(f\"Directory {subset_path} does not exist.\")\n",
    "\n",
    "# List all image files in training, validation, and evaluation directories including food and non-food subdirectories\n",
    "image_files = []\n",
    "\n",
    "for subset in ['training', 'validation', 'evaluation']:\n",
    "    subset_path = os.path.join(dataset_path, subset)\n",
    "    for category in ['food']:\n",
    "        category_path = os.path.join(subset_path, category)\n",
    "        if not os.path.exists(category_path):\n",
    "            print(f\"Directory {category_path} does not exist.\")\n",
    "            continue\n",
    "        for filename in os.listdir(category_path):\n",
    "            if filename.endswith('.jpg'):\n",
    "                image_files.append(os.path.join(subset, category, filename))\n",
    "\n",
    "# Check if we have listed the files correctly\n",
    "print(f\"Total images found: {len(image_files)}\")\n",
    "print(\"First 10 image files:\")\n",
    "print(image_files[:10])\n",
    "\n",
    "# Example function to assign random calorie values between 50 and 500\n",
    "def assign_calories(image_file):\n",
    "    return random.randint(50, 500)\n",
    "\n",
    "# Create a list of dictionaries with filenames and calorie values\n",
    "calorie_data = [{'filename': file, 'calorie': assign_calories(file)} for file in image_files]\n",
    "\n",
    "# Display the first few entries\n",
    "print(\"First 10 entries in calorie_data:\")\n",
    "print(calorie_data[:10])\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "calorie_df = pd.DataFrame(calorie_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "calorie_df.to_csv('calorie_info.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(\"First few rows of calorie_df:\")\n",
    "print(calorie_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692be663-bc4f-4319-b221-800b906a61a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2074a3a0-4813-467a-93e7-c1e9a4addd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1)  # Regression output for calorie estimation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3b933f-35f5-430f-987e-1b7a2fe61d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "# Custom callback to measure epoch duration and estimate remaining time\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.times = []\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        self.times.append(epoch_duration)\n",
    "        average_epoch_time = sum(self.times) / len(self.times)\n",
    "        epochs_remaining = self.params['epochs'] - (epoch + 1)\n",
    "        estimated_time_remaining = epochs_remaining * average_epoch_time\n",
    "        print(f\"Epoch {epoch + 1}/{self.params['epochs']} - Estimated time remaining: {estimated_time_remaining / 60:.2f} minutes\")\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8205a170-2fab-4064-9f80-2aa2e11a1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 validated image filenames.\n",
      "Found 500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training data generator\n",
    "training_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=calorie_df,\n",
    "    directory=dataset_path,\n",
    "    x_col='filename',\n",
    "    y_col='calorie',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,  # Reduced batch size\n",
    "    class_mode='raw',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=calorie_df,\n",
    "    directory=dataset_path,\n",
    "    x_col='filename',\n",
    "    y_col='calorie',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,  # Reduced batch size\n",
    "    class_mode='raw',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87836213-5a0c-4721-8683-6ab7513b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91703\\anaconda3\\anaconda\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626ms/step - loss: 37417.0312 - mae: 155.5754Epoch 1/1 - Estimated time remaining: 0.00 minutes\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 822ms/step - loss: 37314.9062 - mae: 155.3613 - val_loss: 20252.6328 - val_mae: 121.2958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping, time_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8976c1-b8f1-413a-b050-2130ea784d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the model\n",
    "model.save('food_calorie_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba18e876-f77b-422d-9ec6-fe62679393e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "Image: pizza.jpg, Predicted Calorie: 176.27816772460938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict and print name and caloric value\n",
    "def predict_and_print(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_calorie = prediction[0][0]\n",
    "    print(f\"Image: {image_path}, Predicted Calorie: {predicted_calorie}\")\n",
    "\n",
    "# Example usage\n",
    "predict_and_print('pizza.jpg')  # Update with the path to an actual image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
